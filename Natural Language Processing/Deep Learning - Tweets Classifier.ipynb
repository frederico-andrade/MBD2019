{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l56xpzD4YsCp"
   },
   "source": [
    "# Introduction\n",
    " \n",
    "**Playing with Deep Learning**\n",
    "\n",
    "The dataset we have at our disposal includes \"only\" some thousands of tweets. Supposedly, one would think that, to apply Deep Learning techniques, a larger amount of data would be needed (or is it really?)\n",
    "\n",
    "Well, this in not true, or at least, this is not anymore completely true thanks to **Transfer Learning**. If you are training a huge model from scratch, you need a lot of data and GPU time. Lucklily for us, these huge models are already pre-trained for many languages using large datasets (e.g. Wikipedia). In more detail, these models are called **Language Models (LM)** because they are, surprisingly, ... models of your language. LM are trained on a rather simple task: given a sequence of words in a sentence, predict the next one. A properly trained LM should then identify that given the sentence `The dog is`, `black` is more likely than `red` (there are no red dogs). By optimizing this task, what the LM are actually doing is learning the gramatical, lexical and semantical relationships of the language, thus grasping a deep understanding of its textual content. \n",
    "\n",
    "All we have to do is to adapt these LM to our particular domain. In layman words, the LM already speaks English and we need to teach them to talk *Twitterish*. Thousands of tweets are not enough to learn English, but they are definitely enough to learn the nuances of the dataset.\n",
    "\n",
    "The objective now is to create a Classifier. Now, thanks to the LM, it's possible to feed said Classifier with a much more detailed and accurate representation of the input textual content. Therefore, it should be easier to the Classifier to better categorize the textual content.\n",
    "\n",
    "\n",
    "Summing up, my strategy will be:\n",
    "\n",
    "1.   Use a pre-trained English Language Model trained over a large dataset as starting point.\n",
    "2.   Adapt this language model to our domain. To that end, I will retrain the model to learn the particular aspects of the dataset.\n",
    "3. Create a Machine Learning Classifier on top of the dataset language model\n",
    "\n",
    "\n",
    "**Side note: The initial model was trained, by the NLP Course Professor, on Google Colab to be able to use a GPU.For this reason, it is not included anything about the configuration of the GPU or the installation of the required libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KXkLmX5I8xGZ"
   },
   "source": [
    "## Fast AI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h7eq6viH8xGi"
   },
   "source": [
    "To facilitate the training of this deep learning approach, I will make use of the [fast.ai library](https://www.fast.ai/). In particular, the [`text`](https://docs.fast.ai/text.html) module of the fast.ai library contains all the necessary functions. Specifically:\n",
    "\n",
    "- [`text.transform`](https://docs.fast.ai/text.transform.html#text.transform) contains all the scripts to preprocess the data, from raw text to token ids,\n",
    "- [`text.data`](https://docs.fast.ai/text.data.html#text.data) contains the definition of [`TextDataBunch`](https://docs.fast.ai/text.data.html#TextDataBunch), which is the main class we need in NLP,\n",
    "- [`text.learner`](https://docs.fast.ai/text.learner.html#text.learner) contains helper functions to quickly create a language model or an text classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "lxu7CFCv8_xx",
    "outputId": "3ecb536f-f039-47ef-bb7d-35af02cb92d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# I needed this to load data from my GDrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ncGqMmK68xGk"
   },
   "source": [
    "\n",
    "## Training a classifier model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbbEDziH8xGl"
   },
   "source": [
    "To create my model I am going to apply the following steps:\n",
    "\n",
    "1. Fine-tuning an [AWD-LSTM](https://arxiv.org/abs/1708.02182) model to create a language model based on our data.\n",
    "1. Building a classifier based on the learned language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrXdKN9f8xGn"
   },
   "source": [
    "### Reading and viewing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4AmXyT78xGo"
   },
   "source": [
    "First let's import everything we need for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X60QVaOO8xGq"
   },
   "outputs": [],
   "source": [
    "from fastai.text import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kTNNSVb8xG3"
   },
   "source": [
    "I will now read the dataset from the original CSV files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "colab_type": "code",
    "id": "T8pPwgW58xG6",
    "outputId": "53031b40-9b35-428c-ebe6-5a17fccd445b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nuclear%20reactor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navy sidelines 3 newest subs http://t.co/gpVZV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rescuers</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "      <td>VIDEO: 'We're picking up bodies from water': R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hellfire</td>\n",
       "      <td>?????? ??? ?????? ????????</td>\n",
       "      <td>#Allah describes piling up #wealth thinking it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>destroyed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emotionally I am destroyed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>injured</td>\n",
       "      <td>Paterson, New Jersey</td>\n",
       "      <td>Yelp Bolsters Health Care Reviews With Investi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bleeding</td>\n",
       "      <td>dmv ?? fashion school @ KSU.</td>\n",
       "      <td>i hit my foot now my toe is bleeding ??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mudslide</td>\n",
       "      <td>Edinburgh, Scotland</td>\n",
       "      <td>@Pete_r_Knox @Gemmasterful I think the mudslid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>avalanche</td>\n",
       "      <td>Danville, VA</td>\n",
       "      <td>No snowflake in an avalanche ever feels respon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>siren</td>\n",
       "      <td>My subconscious</td>\n",
       "      <td>@stacedemon oh shit!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>detonation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ignition Knock (Detonation) Sensor-Senso Stand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>airplane%20accident</td>\n",
       "      <td>Havenford</td>\n",
       "      <td>+ Nicole Fletcher one of a victim of crashed a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bridge%20collapse</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>@ameenshaikh3 sir i just only wanted to make a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hazard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Battlefield 4 Funny Moments - Dukes of Hazard ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>demolished</td>\n",
       "      <td>QUEENS.</td>\n",
       "      <td>@_STiiiLO I still got video of u demolished</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hail</td>\n",
       "      <td>Hattiesburg, MS</td>\n",
       "      <td>Two great 'dawgs' Dak and Jak !!!  HAIL STATE ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>survived</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Michael5SOS FUCKING LIVE HERE IM SURPRISED IV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>drowning</td>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>I feel like I'm drowning inside my own body!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>collided</td>\n",
       "      <td>Peterborough, Ont.</td>\n",
       "      <td>#Newswatch: 2 vehicles collided at Lock and La...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>panicking</td>\n",
       "      <td>?^åá??åá?^?? ??</td>\n",
       "      <td>OKAY I CAN'T FIND IT SO I'M KINDA PANICKING</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>@ablaze what time does your talk go until? I d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                keyword  ... target\n",
       "0     nuclear%20reactor  ...      0\n",
       "1              rescuers  ...      1\n",
       "2              hellfire  ...      0\n",
       "3             destroyed  ...      0\n",
       "4               injured  ...      1\n",
       "5              bleeding  ...      0\n",
       "6              mudslide  ...      0\n",
       "7             avalanche  ...      0\n",
       "8                 siren  ...      0\n",
       "9            detonation  ...      0\n",
       "10  airplane%20accident  ...      1\n",
       "11    bridge%20collapse  ...      1\n",
       "12               hazard  ...      0\n",
       "13           demolished  ...      0\n",
       "14                 hail  ...      0\n",
       "15             survived  ...      0\n",
       "16             drowning  ...      0\n",
       "17             collided  ...      1\n",
       "18            panicking  ...      0\n",
       "19               ablaze  ...      0\n",
       "\n",
       "[20 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_csv('/content/drive/My Drive/nlp_disaster/data/train.csv', sep=',', index_col=0)\n",
    "training_df = training_df.sample(frac=1).reset_index(drop=True)\n",
    "training_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "uOx1Jmd59Mon",
    "outputId": "b6518ccf-8a4b-4ac1-b17a-273d4ebc44eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword location                                               text\n",
       "id                                                                    \n",
       "0      NaN      NaN                 Just happened a terrible car crash\n",
       "2      NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "3      NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "9      NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('/content/drive/My Drive/nlp_disaster/data/test.csv', sep=',', index_col=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDSdT0CS8xG_"
   },
   "source": [
    "### Getting your data ready for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUCCkCV68xHF"
   },
   "source": [
    "fast.ai provides some helpful loaders to format the input data to the format required by the Deep Learning Model.\n",
    "\n",
    "The main structure we need to create is the [`DataBunch`](https://docs.fast.ai/basic_data.html#DataBunch) that creates the training and validation sets by grabbing the textual data from the required columns.\n",
    "\n",
    "Here we'll use the method <code>from_df</code> of the [`TextList`](https://docs.fast.ai/text.data.html#TextList) to get the data ready for the fine-tuning of the language model and to get the data ready for the classification step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "colab_type": "code",
    "id": "iJO9cY5mPO19",
    "outputId": "9c90fd9f-22e0-4f7b-eda1-71ade1fb623e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxmaj xxunk : xxmaj sick and injured xxunk at a local xxup er are t ... http : / / t.co / xxunk xxbos i hit my foot now my xxunk is bleeding ? ? xxbos xxunk xxunk i think the mudslide cake lady will go and the xxunk will xxunk stay . xxbos xxmaj no xxunk in an avalanche ever feels responsible . xxbos xxunk oh shit ! xxbos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>vote for # xxmaj directioners vs # xxmaj queens in the 5th round of the xxunk # xxunk http : / / t.co / xxmaj xxunk xxbos xxunk xxunk there are bush fires in xxmaj spain like every year one time when we went swimming there were xxunk getting water to fight xxbos xxmaj swansea xxunk hijack transfer move for xxmaj southampton target xxmaj virgil van xxunk http : /</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>peace be upon him ) said ' xxmaj save yourself from xxmaj hellfire even if it is by giving half a date in charity . ' xxbos # hot xxmaj funtenna : hijacking computers to send data as sound waves [ xxmaj black xxmaj hat 2015 ] http : / / t.co / xxunk # prebreak # best xxbos xxunk xxup @un @refugees xxmaj thank you xxup @un and @refugees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>has a lot to do with it xxbos s xxrep 4 o xxup xxunk xxup for xxup ablaze xxrep 4 ? xxunk xxbos xxup disaster xxup averted : xxmaj police kill gunman with xxunk xxunk xxunk http : / / t.co / xxunk xxbos xxmaj sinking the xxmaj xxunk or xxmaj putting the xxmaj boot xxmaj in http : / / t.co / xxunk xxbos xxup the xxup links xxup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>xxbos xxunk _ xxunk xxrep 5 e ! ... but why is it bout to storm tho xxbos xxup xxunk xxunk i hate white people mo xxbos xxunk _ xxunk this here is very true &gt; : xxrep 5 3 xxbos xxmaj photo : xxunk : xxmaj trauma memories are xxunk in images as trauma is a more xxunk than xxunk ... http : / / t.co / xxunk xxbos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Language model data\n",
    "\n",
    "cols=['text']\n",
    "data_lm = (TextList.from_df(training_df, cols=cols)\n",
    "                .split_by_rand_pct(0.2) # 20% Of the dataset for validation\n",
    "                .label_for_lm() # We are training a LM, so the model should predict the next word. This function labels the datas to do that.\n",
    "                .databunch(bs=32) # Batch Size of 32\n",
    "                )\n",
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ks7U_byfH62A"
   },
   "source": [
    "We now have the data in a format that allows for fine-tuning the English language model. However, the final objective is to train a Text Classifier. To that end, we need to also process the data to create another DataBunch, but now for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "krrpTWwMRgqu",
    "outputId": "050ca361-946d-40ea-a598-d45fe2a8f39f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classifier model data\n",
    "\n",
    "target_cols=['target']\n",
    "data_clas = TextClasDataBunch.from_df('.',\n",
    "                                      train_df=training_df[0:-1400], # First tweets for training\n",
    "                                      valid_df=training_df[-1400:], # Last tweets for validation\n",
    "                                      test_df=test_df, # Test dataset\n",
    "                                      vocab=data_lm.vocab,\n",
    "                                      text_cols=cols, # Column with the textual data\n",
    "                                      label_cols=target_cols, # Column with the classification label\n",
    "                                      min_freq=1,\n",
    "                                      bs=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Kny3tdF8xHN"
   },
   "source": [
    "\n",
    "Since this step can be a bit time-consuming, it's best to save the result with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pngiiRE8xHO"
   },
   "outputs": [],
   "source": [
    "data_lm.save('/content/drive/My Drive/nlp_disaster/data/data_lm_export.pkl')\n",
    "data_clas.save('/content/drive/My Drive/nlp_disaster/data/data_class_export.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrlBNkbQ8xHT"
   },
   "source": [
    "You can then reload those results with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lIN1REaO8xHV"
   },
   "outputs": [],
   "source": [
    "data_lm = load_data('/content/drive/My Drive/clarity/nlp_disaster/', 'data_lm_export.pkl')\n",
    "data_clas = load_data('/content/drive/My Drive/clarity/nlp_disaster/','data_class_export.pkl', bs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4jIV2NPE8xHd"
   },
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOGZ-GnU8xHf"
   },
   "source": [
    "We can now use the `data_lm` object created earlier to fine-tune a pretrained language model. [fast.ai](http://www.fast.ai/) has an English model with an [AWD-LSTM architecture](https://arxiv.org/abs/1708.02182) available. To use it, we can create a learner object that will directly create the model, download the pretrained weights and be ready for fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76pJ6TVBXG1H"
   },
   "source": [
    "Neural nets in general, and the AWD_LSTM model in particular, are well know for having a huge number of hyperparameters to optimize. \n",
    "\n",
    "I am deliberately using the default values that fast.ai implements. fast.ai is well know for their superconvergent models that are able to train in just a few steps. This is done through their thoughtful research about initializations, regularization, optimizers and batch normalization. All of these findings are implmented in their default values, so, for most of the tasks, we can safely use them.\n",
    "\n",
    "There is, however, an hyperparameter that requires careful optimization: the learning rate. Learning rate refers to the \"speed\" at which the optimizer is updating the neural net parameters in the backpropagation step. Pick a large learning rate and your NN will never converge. Pick a small rate and you will wait forever to see your NN achive a good performance or to see your NN stuck at a local minima. \n",
    "\n",
    "I will make use of the `lr_find` method in fast.ai to make sense of the values that are optimal for my data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n5pnMyxRYg7x"
   },
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM ,drop_mult=0.5, metrics=[accuracy, Perplexity()]) # Pre-trained AWD_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5RBC55DQYluA"
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "XhpKZ2S0mBn3",
    "outputId": "47c3ddcb-f073-439f-b12e-ec74d4fea8b0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhLmVAhERMKcCoGISJj7f14QXSizAlN6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y8ZCjmtLZnmo"
   },
   "source": [
    "Figure: projection of how the model will perform based on different learning rates.\n",
    "\n",
    "We can see that around 5e-01 the training starts to go south (i.e., the loss/error starts rocketing). The minimal loss is around 1e-1. Nevertheless, we have to choose a value that is approximately in the middle of the sharpest downward slope.\n",
    "\n",
    "The main reason is:\n",
    "\n",
    "> [...] the minimum value is already a bit too high, since we are at the edge between improving and getting all over the place. We want to go one order of magnitude before, a value that's still aggressive (so that we train quickly) but still on the safe side from an explosion.\n",
    "\n",
    "\n",
    "This is given as an indication by the LR Finder tool, so let's try 2e-2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "RVbMmZmg8xHg",
    "outputId": "83762a1d-0562-444b-eb51-0da1368f020d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.139524</td>\n",
       "      <td>3.206456</td>\n",
       "      <td>0.429861</td>\n",
       "      <td>24.691441</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.320149</td>\n",
       "      <td>2.970652</td>\n",
       "      <td>0.464683</td>\n",
       "      <td>19.504629</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.845574</td>\n",
       "      <td>2.905909</td>\n",
       "      <td>0.474851</td>\n",
       "      <td>18.281847</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.541204</td>\n",
       "      <td>2.895627</td>\n",
       "      <td>0.477852</td>\n",
       "      <td>18.094843</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 2e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLC5O_ji8xHk"
   },
   "source": [
    "After just only a handful of epochs we have a pretty good result (i.e., remember that we are still fine-tuning the language model, so guessing right about half of times which is going to be the next word is a pretty good model). It seems that the default values of the library based on the super-convergence approach are just fine. In a more developed solution, we could spend some time trying to optimize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yl1vF5fscBMx"
   },
   "source": [
    "At this point it is important to explain what are we actually training. As I explained before, we have a pre-trained model of the English language. By pretrained, we mean nothing more the Neural Net has a set of weights already learned.\n",
    "This model is quite deep, it has many number of layers with millions of parameters (a.k.a. weights) to learn. It has been posible to train such a huge model, because the entire Wikipedia was used. \n",
    "\n",
    "However, we only have a small bunch of tweets to adapt/fine-tune the model to our domain. Fine-tuning is nothing more than modifying a little bit the weights of the model, so they reflect the particular relationships in our data. But, since our dataset is rather small, if we try to retrain all the layers in the model, we will completely destroy it (the model will catastrophically forget everything learned from Wikipedia). \n",
    "\n",
    "It makes sense that the deeper layers in the model are actually learning the basic aspects of the language, while shallow layers are in charge of more high-level relationships. We do not want to change the deeper layers. Basic language relationships are basically the same in our dataset than in the entire English language (e.g., verb tenses, subject-object relationships). What we actually want to modify is the last layers of the model in charge of learning the high level relationships (e.g. Some disaster is happening somewhere). Well, that's exactly what the default training method in fast.ai is doing: It freezes the deeper layers so you do not modify them while you are fine-tuning your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2tCZIx4pVR-"
   },
   "source": [
    "In the previous step, we have fine-tuned the LM to the particular content of our dataset. To do this, we just trained the last layers in our model to avoid forgetting everything. Now that our model is in a *stable* state (it has learned from our data without losing what learned from Wikipedia), we can further train our model by unfreeze all the layers.\n",
    "\n",
    "The rationale is the following: we can slightly change the weights of all the layers so even the most basic aspects of the language can be redefined according to our data (e.g. Napoleonic wars Wikipedia pages can learn the model that France<-->invade is a likely outcome; however, I do not expect to read anything about a French invasion in the Twitter nowadays). \n",
    "\n",
    "It has been experimentally proven that this process can improve the performane of Deep Learning models (see this [Howard and Ruder's paper](https://arxiv.org/pdf/1801.06146.pdf) for more details). We have to be extremely careful with this process, otherwise we will ruin all our work. To that end, I have reduced my learning rate by an order of magnitude.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "M535Cjn28xHm",
    "outputId": "687bf03a-0e7f-462a-ba95-bf07eaedebac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.409755</td>\n",
       "      <td>2.860762</td>\n",
       "      <td>0.485045</td>\n",
       "      <td>17.474840</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.166371</td>\n",
       "      <td>2.855345</td>\n",
       "      <td>0.492485</td>\n",
       "      <td>17.380424</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, 2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMCYWM-ZtBOH"
   },
   "source": [
    "As shown above, with only 2 epochs, the model has been improved already.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j4DYmf_G8xHs"
   },
   "source": [
    "To understand what our language model is learning, you can run the [`Learner.predict`](https://docs.fast.ai/basic_train.html#Learner.predict) method and specify the number of words you want it to guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "60xLjz1D8xHu",
    "outputId": "8bbfecd2-7fb0-4384-b961-e87042721758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haha South Tampa Being Burned ( ? ) in drought - Pakistan - India http : / / t.co / why # Myanmar\n",
      "Haha South Tampa Some Gang Who Try to Riot : The Murderous Story Of americaûªs First Hijacking\n",
      "Haha South Tampa her meltdown during Da Apocalypse # soundcloud ? http : / / t.co / EDM xxbos tired now my example is exploded\n",
      "Haha South Tampa to dance lungs ? xxbos drive yours \n",
      "  Buses are always linked to the lives of rioting fans or fans . xxbos Multiple\n",
      "Haha South Tampa ! ? \n",
      " \n",
      "  http : / / t.co / 06 Pandemonium xxbos People are finally in the middle of our population in #\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "  print(learn.predict(\"Haha South Tampa\", n_words=25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khzniEGX8xHz"
   },
   "source": [
    "It doesn't make much sense (we have a tiny vocabulary here and didn't train much on it) but note that it respects basic grammar (which comes from the pretrained model) while it has adapted the conversation to the content of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1zUkM4xZuI4B"
   },
   "source": [
    "\n",
    "I could futher train or experiment with more hyperparameters, but since the language model is not the final outcome and the LM seems good enough, I will move on to the classification step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTQymGWCuOLX"
   },
   "source": [
    "We can save the model for later uses. We need to save the encoder (the part that given a textual content creates the representation) which is the only part of the model needed for classification in the next section (i.e., the other part is the decoder in charge of translating the textual representation back to the text again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIVKMQ688xH0"
   },
   "outputs": [],
   "source": [
    "learn.save_encoder('/content/drive/My Drive/nlp_disaster/models/ft_enc_extended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a38ilFdZ8xH4"
   },
   "source": [
    "### Building a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaT8zAK08xH5"
   },
   "source": [
    "It's now time to actually create the classifier taking our fine-tuned encoder. For this step we need the `data_clas` object we created earlier.\n",
    "\n",
    "For this step, I will use again the default values in fast.ai to create a classification model. In this case, I will use the `text_classifier_learner`. We need to also tell the classifier that we want to use the fine-tuned encoder that we have just learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prrNRWVC8xH7"
   },
   "outputs": [],
   "source": [
    "learn_class = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.8, metrics=[accuracy,FBeta(beta=1)])\n",
    "learn_class.load_encoder('/content/drive/My Drive/nlp_disaster/models/ft_enc_extended')\n",
    "learn_class.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzBnpJMCox7D"
   },
   "source": [
    "I will plot again the learning rate to understand which one makes sense for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "6-F9CfhP430M",
    "outputId": "1da85da1-cedf-487b-a91f-beaab6433460"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='91' class='' max='194', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      46.91% [91/194 00:03<00:03 0.9753]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_class.lr_find()\n",
    "learn_class.recorder.plot(skip_end=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ej0rANCquU09"
   },
   "source": [
    "Thanks to fast.ai super-convergence strategies, I think that just a small number of epochs should be enough. Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "Ou8W_Imd8xIJ",
    "outputId": "2c709c43-397c-4f31-815c-595b872da994"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.587017</td>\n",
       "      <td>0.458607</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.731261</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.559021</td>\n",
       "      <td>0.456950</td>\n",
       "      <td>0.793571</td>\n",
       "      <td>0.739405</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.541131</td>\n",
       "      <td>0.449950</td>\n",
       "      <td>0.801429</td>\n",
       "      <td>0.749098</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_class.fit_one_cycle(3, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Io2s9yiImVAH"
   },
   "outputs": [],
   "source": [
    "learn_class.save('/content/drive/My Drive/nlp_disaster/models/1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iz7J-croud_D"
   },
   "source": [
    "Great! 80% of accuracy.\n",
    "\n",
    "As in the language modeling training, we have just trained the last layers of the model, we can gradually unfreeze the rest of the model and train it together.\n",
    "\n",
    "In this case I will not unfreeze all the model at a time, but in different steps. This gradual unfreezing has been experimentally proven to improve the training process (again, check Howard and Ruder's paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "twCBr7mL8xIO",
    "outputId": "12e62b4f-81c9-4169-ee29-36b481a66e77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.532755</td>\n",
       "      <td>0.449707</td>\n",
       "      <td>0.796429</td>\n",
       "      <td>0.733396</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.525082</td>\n",
       "      <td>0.440217</td>\n",
       "      <td>0.806429</td>\n",
       "      <td>0.761653</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.494378</td>\n",
       "      <td>0.434785</td>\n",
       "      <td>0.807857</td>\n",
       "      <td>0.762157</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_class.freeze_to(-2)\n",
    "learn_class.fit_one_cycle(3, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QL-ALzPzmbwO"
   },
   "outputs": [],
   "source": [
    "learn.save('/content/drive/My Drive/clarity/models/2nd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "nzpVi542mle_",
    "outputId": "df7655f9-b877-4ba2-c501-c77a8576dae7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.490811</td>\n",
       "      <td>0.436761</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.762162</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.481934</td>\n",
       "      <td>0.436474</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.758432</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.483669</td>\n",
       "      <td>0.435457</td>\n",
       "      <td>0.807857</td>\n",
       "      <td>0.752530</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_class.freeze_to(-3)\n",
    "learn_class.fit_one_cycle(3, slice(1e-3/2/(2.6**4),1e-3/3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-Z_xXW_mpWG"
   },
   "outputs": [],
   "source": [
    "learn_class.save('/content/drive/My Drive/clarity/models/3rd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "iv7j5dnEFsWi",
    "outputId": "8e6da7cf-ca85-4dd6-eb94-7d981ca36bf6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f_beta</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.467295</td>\n",
       "      <td>0.437380</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.753488</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.471852</td>\n",
       "      <td>0.433497</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.764286</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485653</td>\n",
       "      <td>0.436482</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.746241</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.470964</td>\n",
       "      <td>0.431472</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.774306</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.466982</td>\n",
       "      <td>0.432327</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.755475</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.466522</td>\n",
       "      <td>0.431400</td>\n",
       "      <td>0.815714</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.456885</td>\n",
       "      <td>0.435905</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.460334</td>\n",
       "      <td>0.430711</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.462109</td>\n",
       "      <td>0.435370</td>\n",
       "      <td>0.806429</td>\n",
       "      <td>0.748375</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.437699</td>\n",
       "      <td>0.431185</td>\n",
       "      <td>0.812857</td>\n",
       "      <td>0.766488</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_class.unfreeze()\n",
    "learn_class.fit_one_cycle(10, slice(1e-3/10/(2.6**4),1e-3/10), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0moaKqhImyLI"
   },
   "outputs": [],
   "source": [
    "learn_class.save('/content/drive/My Drive/clarity/models/classifier_5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02DIp2_ov37s"
   },
   "source": [
    "As can be seen in the results, our model is now offering accuracies up to 81%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIJKAxsP8xIX"
   },
   "source": [
    "Again, we can predict on a raw text (the category in this case) by using the [`Learner.predict`](https://docs.fast.ai/basic_train.html#Learner.predict) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Zpp13v1N8xIY",
    "outputId": "62b60e24-5ac3-48b4-e47d-5e550f595eda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 1, tensor(1), tensor([0.0674, 0.9326]))"
      ]
     },
     "execution_count": 261,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_class.predict(\"VIDEO: 'We're picking up bodies from water': Rescuers are searching for hundreds of migrants in the Mediterran... http://t.co/ciwwUQthin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WzoYq3gQ1A7z"
   },
   "source": [
    "The predicted category is 1 (Disaster Tweet) and the model is 93% sure about it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZTY2buWwMBx"
   },
   "source": [
    "In order to have a full report of this model performance, I will ask the model to offer me all the predictions and inspect the confusion matrix and the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "LglwOWs5iUuh",
    "outputId": "f6a24442-61ac-4e5b-ab0f-66412d53f8f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>708</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1\n",
       "row_0          \n",
       "0      708  169\n",
       "1       93  430"
      ]
     },
     "execution_count": 367,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get predictions\n",
    "preds, targets = learn_class.get_preds()\n",
    "\n",
    "predictions = np.argmax(preds, axis = 1)\n",
    "pd.crosstab(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "0PugeNbGkWF6",
    "outputId": "0b402b0f-6a97-42ec-8747-f6c4ea6e3bea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       801\n",
      "           1       0.82      0.72      0.77       599\n",
      "\n",
      "    accuracy                           0.81      1400\n",
      "   macro avg       0.81      0.80      0.81      1400\n",
      "weighted avg       0.81      0.81      0.81      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targets, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EE_Z3qRwfZ3"
   },
   "source": [
    "As can be seen in both the confusion matrix and in the classification report, the model is better not only in terms of accuracy, but also in its performance for all the classes when compared to the non Deep Learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FPE9ufJowcT2"
   },
   "source": [
    "Finally, saving the model object to reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Zdg1Ay2ho97"
   },
   "outputs": [],
   "source": [
    "learn_class.save('/content/drive/My Drive/clarity/models/final_class_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CL9fW9mmBZQg"
   },
   "source": [
    "Finally, lets create the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "akJ5FiYXAXI9",
    "outputId": "ff9eb791-ed25-4328-e52f-c30b064d7c50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, y, losses = learn_class.get_preds(ds_type=DatasetType.Test, with_loss=True)\n",
    "y = torch.argmax(preds, dim=1)\n",
    "submission = pd.DataFrame({'id': test_df.index, 'target': y})\n",
    "submission.to_csv('submission_fastai.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DgMvfxmUBjKL"
   },
   "source": [
    "The final accuracy in Kaggle is 0.81"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "deep_learning_solution.ipynb",
   "provenance": []
  },
  "jekyll": {
   "keywords": "fastai",
   "summary": "Application to NLP, including ULMFiT fine-tuning",
   "title": "text"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
